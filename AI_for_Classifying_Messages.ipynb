{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV file into a pandas dataframe\n",
        "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1dFdlvgmyXfN3SriVn5Byv_BNtyroICxdgrQKBzuMA1U/export?format=csv&id=1dFdlvgmyXfN3SriVn5Byv_BNtyroICxdgrQKBzuMA1U&gid=0\")\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(df['message'], df['sentiment'], test_size=0.2)\n",
        "\n",
        "# Preprocess the labels by encoding them as integer values\n",
        "encoder = LabelEncoder()\n",
        "train_labels = encoder.fit_transform(train_labels)\n",
        "test_labels = encoder.transform(test_labels)\n",
        "\n",
        "# Tokenize the messages using the TensorFlow Tokenizer\n",
        "#tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
        "new_train_data=[]\n",
        "#clean data\n",
        "for d in train_data:\n",
        "  d=str(d)\n",
        "  new_train_data.append(d)\n",
        "\n",
        "new_test_data=[]\n",
        "for d in test_data:\n",
        "  d=str(d)\n",
        "  new_test_data.append(d)\n",
        "\n",
        "# Tokenize the messages using the TensorFlow Tokenizer\n",
        "tokenizer.fit_on_texts(new_train_data)\n",
        "train_data = tokenizer.texts_to_matrix(new_train_data)\n",
        "test_data = tokenizer.texts_to_matrix(new_test_data)\n",
        "\n",
        "#Define the neural network model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(train_data, train_labels)\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_data=(test_data, test_labels))\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLKDL82FLLuR",
        "outputId": "a108d554-b7fe-423d-9509-576717f24130"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]] [1 1 5 ... 5 1 5]\n",
            "Epoch 1/10\n",
            "4710/4710 [==============================] - 24s 5ms/step - loss: 1.2924 - accuracy: 0.4771 - val_loss: 1.2578 - val_accuracy: 0.4924\n",
            "Epoch 2/10\n",
            "4710/4710 [==============================] - 19s 4ms/step - loss: 1.2254 - accuracy: 0.5066 - val_loss: 1.2497 - val_accuracy: 0.4977\n",
            "Epoch 3/10\n",
            "4710/4710 [==============================] - 19s 4ms/step - loss: 1.1883 - accuracy: 0.5240 - val_loss: 1.2580 - val_accuracy: 0.4957\n",
            "Epoch 4/10\n",
            "4710/4710 [==============================] - 17s 4ms/step - loss: 1.1537 - accuracy: 0.5406 - val_loss: 1.2670 - val_accuracy: 0.4930\n",
            "Epoch 5/10\n",
            "4710/4710 [==============================] - 18s 4ms/step - loss: 1.1217 - accuracy: 0.5555 - val_loss: 1.2878 - val_accuracy: 0.4928\n",
            "Epoch 6/10\n",
            "4710/4710 [==============================] - 19s 4ms/step - loss: 1.0946 - accuracy: 0.5693 - val_loss: 1.3028 - val_accuracy: 0.4878\n",
            "Epoch 7/10\n",
            "4710/4710 [==============================] - 17s 4ms/step - loss: 1.0703 - accuracy: 0.5800 - val_loss: 1.3228 - val_accuracy: 0.4823\n",
            "Epoch 8/10\n",
            "4710/4710 [==============================] - 19s 4ms/step - loss: 1.0488 - accuracy: 0.5904 - val_loss: 1.3389 - val_accuracy: 0.4815\n",
            "Epoch 9/10\n",
            "4710/4710 [==============================] - 17s 4ms/step - loss: 1.0302 - accuracy: 0.5973 - val_loss: 1.3746 - val_accuracy: 0.4759\n",
            "Epoch 10/10\n",
            "4710/4710 [==============================] - 18s 4ms/step - loss: 1.0133 - accuracy: 0.6052 - val_loss: 1.3889 - val_accuracy: 0.4764\n",
            "1178/1178 [==============================] - 2s 2ms/step - loss: 1.3889 - accuracy: 0.4764\n",
            "Test accuracy: 0.4763509929180145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "helper = {1:\"Curious to dive deeper\", \n",
        "          6:\"Sad\",\n",
        "          7:\"Surprised\",\n",
        "          5:\"Neutral\",\n",
        "          4:\"Happy\",\n",
        "          3:\"Fearful\",\n",
        "          0:\"Angry\"}"
      ],
      "metadata": {
        "id": "X15j1bldqZEW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example test\n",
        "random_str = \"Which I find surprising since the US seems to prefer american football more.\""
      ],
      "metadata": {
        "id": "_A0LujVjsopF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = helper[np.argmax(model.predict(tokenizer.texts_to_matrix([random_str])))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82flZT_AhzOq",
        "outputId": "6d0011b7-95f5-4c34-e792-3d358c4ea931"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25KVs7bqsw_Y",
        "outputId": "a2d3b193-1529-4c80-ea47-eddd45f4b0b8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ev13XPIXt9pJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}